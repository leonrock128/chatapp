# ğŸ’¬ ChatApp â€“ AI Chat Assistant

This is a simple full-stack AI chatbot project built using **FastAPI (Python)** for the backend and **React (Vite)** for the frontend.  
It uses the **Groq Llama-3.1-8B-Instant** model to generate intelligent chat responses.

---

## ğŸš€ Tech Stack

| Technology | Description |
|-------------|--------------|
| ğŸ§  **AI Model** | Groq Llama-3.1-8B-Instant |
| âš™ï¸ **Backend** | FastAPI (Python) |
| ğŸ’» **Frontend** | React (Vite) |
| â˜ï¸ **Deployment** | Render (Backend) & Vercel (Frontend) |

---

## âœ¨ Features

âœ… FastAPI backend with REST API  
âœ… React (Vite) frontend  
âœ… Real-time intelligent chat using Groq API  
âœ… Simple conversation management  
âœ… CORS enabled for frontend-backend communication  
âœ… Fully deployed and accessible online

---

## ğŸ“‚ Project Structure
```
chatapp/
â”œâ”€â”€ Backend/
â”‚ â”œâ”€â”€ app.py
â”‚ â”œâ”€â”€ .env
â”‚ â”œâ”€â”€ requirements.txt
â””â”€â”€ Frontend/
â”œâ”€â”€ src/
â”œâ”€â”€ package.json
â”œâ”€â”€ vite.config.js
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone Repository
```
git clone https://github.com/leonrock128/chatapp.git
cd chatapp
```

### 2ï¸âƒ£ Setup Backend
```
cd Backend
```

Create and activate a virtual environment:
```
conda create -n chatbot python=3.11
conda activate chatbot
```
Install dependencies:
```
pip install -r requirements.txt
```


Create a .env file inside backend/:
```
GROQ_API_KEY=your_groq_api_key_here

```

Run Backend:
```
uvicorn app:app --reload
```

---

### 3ï¸âƒ£ Setup Frontend
```
cd Frontend
npm install
```
Create a .env file inside frontend/:
```
VITE_BACKEND_URL=http://127.0.0.1:8000
```

Run Frontend:
```
npm run dev
```

---

## API Usage Example
**POST /chat/**  

**Request:**
```
{
  "message": "Hello!",
  "role": "user",
  "conversation_id": "12345"
}
```
**Response:**
```
{
  "response": "Hi there! How can I help you today?",
  "conversation_id": "12345"
}
```

---

### ğŸŒ Live Demo

 [View Live ChatApp](https://chatapp-frontend-lovat-delta.vercel.app/)
